\section{Evaluation}
\label{sec:results}

In this section, we evaluate the performance of Matrix through
simulations.

\subsection{Simulation setup}\label{subsec:sim}

Matrix was implemented as a subroutine of CTP in TinyOS \cite{tinyos}
and the experiments were run using the TOSSIM simulator~\cite{tossim}. We
compare Matrix with and without the local broadcast mechanism, to which we refer
as MHCL (note that the implementation is
different from that in \cite{2016techreport}, where it was implemented as a
subroutine of RPL). RPL was implemented in Contiki \cite{Dunkels:2004} and was
simulated on Cooja~\cite{Eriksson:2009}. Table \ref{tab:conf} lists the default
simulation parameters used for each protocol, in a non-faulty scenario. We use the $LinkLayerModel$ tool from TinyOS to generate the topology and connectivity model. 
We simulated a range of faulty scenarios, based on experimental data collected
from TelosB sensor motes, deployed in an outdoor
environment \cite{Baccour:2012}. In each scenario, after every 60 seconds of
simulation, each node shutdowns its radio with probability $\sigma$ and keeps
the radio off for a time interval uniformly distributed in
$[\varepsilon - 5, \varepsilon + 5]$ seconds (see Table~\ref{tab:scn}).
The first scenario ($Scn1$) represents a network without node failures. The
remaining scenarios represent a combination of values of $\sigma$ and
$\varepsilon$. Note that these are all node-failure scenarios, which are
significantly harsher than models that simulate link or per-packet
failures only.

On top of the network layer, we ran an application, in which each node
sends 10 messages to the root, and the root relies with an ack. Nodes start sending application messages 90 seconds after the simulation has started. The entire
simulation takes 20 minutes. Each simulation was run 10 times. In each plot,
the curve or bars represent the average, and the error bars the confidence
interval of 95\%.

\begin{table}[!ht]
\centering
\caption{Simulation parameters}
\label{tab:conf}
\begin{tabular}{@{}lc@{}}
\toprule
\multicolumn{1}{l}{\textbf{Parameter}} & \textbf{Value} \\ \midrule
Base Station                           & 1 center       \\
Number of Nodes                        & 100            \\
Radio Range ($m$)                      & 100            \\
Density ($nodes/m^{2}$)                & 10             \\
Number of experiments                              & 10             \\
Path Loss Exponent                     & 4.7            \\
Power decay (dB)                       & 55.4           \\
Shadowing Std Dev (dB)                 & 3.2            \\
Simulation duration                 & 20 min            \\
Application messages (node to root + ack)  & 10 per node \\
Max. Routing table size & 20 entries \\
\bottomrule
\end{tabular}
\end{table}

\begin{table}[]
\centering
\caption{Faulty network scenarios}
\label{tab:scn}
\begin{tabular}{|c|c|c|c|}
\hline
\textbf{$\sigma$$\setminus$$\varepsilon$} & \textbf{10 sec.} & \textbf{20 sec.} & \textbf{40 sec.}\\ \hline
\textbf{1\%}     & Scenario 2            & Scenario 3        & Scenario 4              \\ \hline
\textbf{5\%}     & Scenario 5            & Scenario 6        & Scenario 7             \\ \hline
\textbf{10\%}    & Scenario 8            & Scenario 9        & Scenario 10              \\ \hline
\end{tabular}
\end{table}


\subsection{Results}\label{subsec:res}

Firstly, we turn our attention to memory efficiency of each protocol.
To evaluate the usage of routing tables, we compare the number of entries used
by each protocol. Each node was allocated a routing table of equal maximum size:
20 entries.
In Figure \ref{fig:table-usage}, we show the CDFs (cumulative distribution
functions) of the percentage of routing table usage among nodes\footnote{We
measured the routing table usage of each node in one-minute intervals, then
took the average over 20 minutes. }), and compare Matrix,
RPL, and MHCL.
In this plot, Matrix was simulated in the faulty scenario \#10 (Table \ref{tab:scn}).
Note that $>35\%$ of nodes are leaves,
i.e., do not have any descendants in the collection tree topology,
and therefore use zero routing table entries.
As we can see, RPL is the only protocol that uses 100\% of table
entries for some nodes ($\geq30\%$ of nodes have their tables full).
This is due to the fact that RPL, in the storing mode, pro-actively
maintains an entry in the routing table of every node on the path
from the root to each destination, which quickly fills the available
memory and forces packets to be dropped. 
The difference between MHCL and Matrix is small: MHCL
stores only the IPtree structure, whereas Matrix stores IPtree and
RCtree data; the latter is kept only temporarily during parent
changes in the collection tree, so its average memory usage is low.

\begin{figure}[h]
    \centering
    \includegraphics[width=0.95\linewidth]{Images/tableentries.pdf}
    \caption{Routing table usage CDF. (Maximum table size = 20)}
    \label{fig:table-usage}
\end{figure}

Figure \ref{fig:beacons} illustrates the amount of control traffic
in our experiments (the total number of beacons sent during the entire
simulation).
Matrix sends fewer control packet than RPL, because it
only sends additional beacons during network initialization and in
case of collection tree topology updates, whereas RPL has a communication
intensive maintenance of downward routes during the entire execution time. 

\begin{figure}[h]
    \centering
    \includegraphics[width=0.95\linewidth]{Images/beacons.pdf}
    \caption{Number of control packets.}
    \label{fig:beacons}
\end{figure}

Figure~\ref{fig:footprint} compares RAM and ROM footprints in
the protocol stack of CTP, RPL and Matrix. We can see that Matrix adds only a
little more than 7KB of code to CTP, allowing this protocol to perform any-to-any communication with
high scalability. When compared with RPL, the execution code of
Matrix requires less RAM.
\begin{figure}[h]
    \centering
    \includegraphics[width=0.82\linewidth]{Images/footprint.pdf}
    \caption{Code and memory footprint in bytes.}
    \label{fig:footprint}
\end{figure}

Our main result is illustrated in Figure~\ref{fig:txdwn}, which compares
top-down routing success rate. We measured the total
number of application (ack) messages sent downwards and successfully received by
the destination.\footnote{We do not plot the success rate of bottom-up traffic,
since it is done by the underlying collection protocol, without any intervention from Matrix
.} In the plot, ``inevitable losses'' refers to the
number of messages that were lost due to a failure of the destination node, in which case, there were no
valid path to the destination and the packet loss was inevitable.
The remaining messages were lost due to wireless collisions and node failures on
the packet's path. 

We can see that, when a valid path exists to the destination, the top-down
success rate of Matrix varies between 95\% and 99\%. In the harshest
faulty scenario 10,
without the local broadcast mechanism, MHCL delivers 85\% of top-down messages.
With the local broadcast activated, the success rate increases to 95\%,
i.e., roughly 2/3 of otherwise lost messages succeed in reaching the final
destination.
RPL, on the other hand, delivered less than $20\%$ of messages in all simulated
scenarios, which occurs due to lack of memory to store all the top-down routes.

\begin{figure}[h]
    \centering
    \includegraphics[width=1\linewidth]{Images/txrouting.pdf}
    \caption{Top-down routing success rate.}
    \label{fig:txdwn}
\end{figure}
